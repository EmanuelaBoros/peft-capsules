{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ec3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUVELLES', 'SUISSES', '—', 'En', '1887', ',', 'la', 'Société', 'suisse', 'du', 'Grutli', 's', \"'\", 'est', 'accrue', 'de', '40', 'sections', ';', 'l', \"'\", 'association', 'compte', 'actuellement', '12,000', 'membres']\n",
      "['O', 'O', 'O', 'B-time', 'I-time', 'O', 'O', 'B-org', 'I-org', 'I-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "{'date': '1888-01-09', 'language': 'fr', 'document_type': 'newspaper', 'dataset': 'hipe2020', 'original_source': 'v1.4.1/fr/HIPE-data-v1.4.1-train-fr.tsv', 'doi': 'https://zenodo.org/record/6046853', 'version': 'v1.4', 'original_license': 'CC-BY-NC-SA 4.0', 'publication_title': 'EXP'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import ast\n",
    "\n",
    "dataset = load_dataset(\"hipe/2022-data\", dataset='hipe2020', language='fr')\n",
    "\n",
    "# Convert the 'metadata' string to a dictionary for each entry in the dataset\n",
    "for i, item in enumerate(dataset['train']):\n",
    "    metadata_string = item['metadata']\n",
    "    metadata_dict = ast.literal_eval(metadata_string)\n",
    "    dataset['train'][i]['metadata'] = metadata_dict\n",
    "\n",
    "# Example usage\n",
    "print(dataset['train'][0]['sentences']['tokens'][0])  # Tokens of the first sentence in the first article\n",
    "print(dataset['train'][0]['sentences']['NE-COARSE-LIT'][0])  # Coarse labels for the tokens in the first sentence\n",
    "print(dataset['train'][0]['metadata'])  # Metadata as a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c4365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITESPACE_RULES = {\n",
    "    \"fr\": {\n",
    "        \"punctuation_nows_before\": [\".\", \",\", \")\", \"]\", \"}\", \"°\", \"...\"],\n",
    "        \"punctuation_nows_after\": [\"(\", \"[\", \"{\"],\n",
    "        \"punctuation_nows_beforeafter\": [\"'\", \"-\"],\n",
    "        \"punctuation_ciffre\": [\".\", \",\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "def reglue_tokenized_text(tokens: list[str]) -> str:\n",
    "    \"\"\"Reglue a tokenized text back together.\n",
    "\n",
    "    Args:\n",
    "        tokens (list[str]): List of tokens.\n",
    "        language (str): Language of the text.\n",
    "\n",
    "    Returns:\n",
    "        str: Reglued text.\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return \"\"\n",
    "\n",
    "    # if language not in WHITESPACE_RULES:\n",
    "    #     # Default behavior for languages without specific rules: join with space\n",
    "    #     return \" \".join(tokens)\n",
    "\n",
    "    wsrules = WHITESPACE_RULES[\"fr\"]\n",
    "    text = tokens[0]\n",
    "\n",
    "    for i in range(1, len(tokens)):\n",
    "        prev_token = tokens[i - 1]\n",
    "        curr_token = tokens[i]\n",
    "        insert_ws = True\n",
    "\n",
    "        if (\n",
    "            prev_token in wsrules[\"punctuation_nows_beforeafter\"]\n",
    "            or curr_token in wsrules[\"punctuation_nows_beforeafter\"]\n",
    "        ):\n",
    "            insert_ws = False\n",
    "\n",
    "        elif curr_token in wsrules[\"punctuation_nows_before\"]:\n",
    "            insert_ws = False\n",
    "\n",
    "        elif prev_token in wsrules[\"punctuation_nows_after\"]:\n",
    "            insert_ws = False\n",
    "\n",
    "        elif (\n",
    "            prev_token in wsrules[\"punctuation_ciffre\"]\n",
    "            and i >= 2\n",
    "            and tokens[i - 2].isdigit()\n",
    "            and curr_token.isdigit()\n",
    "        ):\n",
    "            insert_ws = False\n",
    "\n",
    "        text += \" \" + curr_token if insert_ws else curr_token\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5374df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk import pos_tag\n",
    "from nltk.tree import Tree\n",
    "import string\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc2dde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fr.wikipedia.org/wiki/Berne\n"
     ]
    }
   ],
   "source": [
    "from wikidata.client import Client\n",
    "\n",
    "client = Client()\n",
    "entity = client.get('Q70', load=True)\n",
    "\n",
    "url = entity.data['sitelinks']['frwiki']['url']\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468aa407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(tokens, tags, nel_lit, nel_meto):\n",
    "    \"\"\"postprocess the outputs here, for example, convert predictions to labels\n",
    "    [\n",
    "        {\n",
    "            \"entity\": \"B-org.ent.pressagency.AFP\",\n",
    "            \"score\": 0.99669313,\n",
    "            \"index\": 13,\n",
    "            \"word\": \"AF\",\n",
    "            \"start\": 43,\n",
    "            \"end\": 45,\n",
    "        },\n",
    "        {\n",
    "            \"entity\": \"I-org.ent.pressagency.AFP\",\n",
    "            \"score\": 0.42747754,\n",
    "            \"index\": 14,\n",
    "            \"word\": \"##P\",\n",
    "            \"start\": 45,\n",
    "            \"end\": 46,\n",
    "        },\n",
    "    ]\n",
    "    [[('AFP', 'org.ent.pressagency.AFP', (12, 13), (47, 50))]]\n",
    "    \"\"\"\n",
    "    tags = [tag.replace(\"S-\", \"B-\").replace(\"E-\", \"I-\") for tag in tags]\n",
    "    pos_tags = [pos for token, pos in pos_tag(tokens)]\n",
    "\n",
    "    conlltags = [(token, pos, tg) for token, pos, tg in zip(tokens, pos_tags, tags)]\n",
    "    ne_tree = conlltags2tree(conlltags)\n",
    "\n",
    "    entities = []\n",
    "    idx: int = 0\n",
    "\n",
    "    for subtree in ne_tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            original_label = subtree.label()\n",
    "            original_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            \n",
    "            if nel_lit[idx] not in ['NIL', '_']:\n",
    "                qid = nel_lit[idx]\n",
    "                try:\n",
    "                    entity = client.get(qid, load=True)\n",
    "                    correct_name = entity.data['labels']['fr']['value']\n",
    "                except Exception as ex:\n",
    "                    print('Could not decode', qid, original_string, '---', ex)\n",
    "                    \n",
    "                    correct_name = original_string\n",
    "                entities.append(\n",
    "                    {\n",
    "                        \"index\": idx,\n",
    "                        \"entity\": original_label,\n",
    "                        \"word\": original_string,\n",
    "                        \"qid\": qid,\n",
    "                        \"wikipedia\": correct_name\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                entities.append(\n",
    "                    {\n",
    "                        \"index\": idx,\n",
    "                        \"entity\": original_label,\n",
    "                        \"word\": original_string,\n",
    "                    }\n",
    "                )\n",
    "            idx += len(subtree)\n",
    "\n",
    "            # Update the current character position\n",
    "            # We add the length of the original string + 1 (for the space)\n",
    "        else:\n",
    "            token, pos = subtree\n",
    "            # If it's not a named entity, we still need to update the character\n",
    "            # position\n",
    "            idx += 1\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04eaff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail(original_string, entities, detail_type):\n",
    "    \"\"\"\n",
    "    Get the function for a person from a list of entities.\n",
    "\n",
    "    :param original_string: The original string representing a person.\n",
    "    :param entities: A list of entities, where each entity is represented as\n",
    "                     a list [text, type, start_position, end_position].\n",
    "    :return: The function of the person if found, otherwise None.\n",
    "    \"\"\"\n",
    "#     {'index': 18, 'entity': 'time', 'word': 'du 17 novembre 1885'}\n",
    "#     print(entities)\n",
    "#     print(original_string, detail_type)\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_text, entity_type = entity['word'], entity['entity']\n",
    "        if detail_type in entity_type and entity_text in original_string:\n",
    "#             print(entity['word'])\n",
    "#             print('-'*30)\n",
    "            return entity['word']\n",
    "#     print('-'*30)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d570ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# for document in dataset['train']:\n",
    "#     sentences = document['sentences']\n",
    "#     metadata = ast.literal_eval(document['metadata'])\n",
    "#     print(type(metadata))\n",
    "    \n",
    "#     # Extract the date from the metadata\n",
    "#     date = metadata.get('date', 'Unknown Date')\n",
    "    \n",
    "#     for tokens, coarse_lit, coarse_meto, fine_lit, file_meto, fine_comp, ne_nested in zip(sentences['tokens'], \n",
    "#                              sentences['NE-COARSE-LIT'], sentences['NE-COARSE-METO'], sentences['NE-FINE-LIT'], \n",
    "#                              sentences['NE-FINE-METO'], sentences['NE-FINE-COMP'], sentences['NE-NESTED']):\n",
    "#         entities = [get_entities(tokens, tags) for tags in [coarse_lit, coarse_meto, fine_lit, file_meto, fine_comp, ne_nested]]\n",
    "\n",
    "#         print(f\"Date: {date}, Entities: {entities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf92136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/158 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tokens, coarse_lit, coarse_meto, fine_lit, fine_meto, fine_comp, ne_nested, nel_lit, nel_meto \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     27\u001b[0m     sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-COARSE-LIT\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-COARSE-METO\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     28\u001b[0m     sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-FINE-LIT\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-FINE-METO\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-FINE-COMP\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE-NESTED\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m     sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEL-LIT\u001b[39m\u001b[38;5;124m'\u001b[39m], sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEL-METO\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m ):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tags \u001b[38;5;129;01min\u001b[39;00m [fine_lit, fine_meto, fine_comp, ne_nested]:\n\u001b[0;32m---> 32\u001b[0m         entities \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mget_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnel_lit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnel_meto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[1;32m     35\u001b[0m     entity_type \u001b[38;5;241m=\u001b[39m entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[14], line 40\u001b[0m, in \u001b[0;36mget_entities\u001b[0;34m(tokens, tags, nel_lit, nel_meto)\u001b[0m\n\u001b[1;32m     38\u001b[0m qid \u001b[38;5;241m=\u001b[39m nel_lit[idx]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     entity \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     correct_name \u001b[38;5;241m=\u001b[39m entity\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikidata/client.py:140\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, entity_id, load)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentity_map[entity_id] \u001b[38;5;241m=\u001b[39m entity\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mentity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m entity\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikidata/entity.py:261\u001b[0m, in \u001b[0;36mEntity.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    260\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./wiki/Special:EntityData/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 261\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m EntityState\u001b[38;5;241m.\u001b[39mnon_existent\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikidata/client.py:194\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    192\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: no cache; make a request...\u001b[39m\u001b[38;5;124m'\u001b[39m, url)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    196\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP error code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, e\u001b[38;5;241m.\u001b[39mcode, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1346\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1257\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1255\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1303\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1252\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1012\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1015\u001b[0m \n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:952\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 952\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1422\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:923\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    922\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:831\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    830\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 831\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    833\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming dataset and get_entities are already defined\n",
    "\n",
    "# Dictionaries to store entity statistics\n",
    "entities_per_year = defaultdict(int)\n",
    "entities_per_decade = defaultdict(int)\n",
    "entity_decade_appearances = defaultdict(set)\n",
    "entity_year_appearances = defaultdict(set)  # To track in which years each entity appears\n",
    "unique_entity_types = set()  # To track unique entity types\n",
    "\n",
    "for document in tqdm(dataset['train'], total=len(dataset['train'])):\n",
    "    metadata = ast.literal_eval(document['metadata'])\n",
    "    date = metadata.get('date')\n",
    "    \n",
    "    if not date:\n",
    "        continue  # Skip documents without a date\n",
    "\n",
    "    year = int(date[:4])\n",
    "    decade = year - (year % 10)\n",
    "\n",
    "    sentences = document['sentences']\n",
    "    entities = []\n",
    "    for tokens, coarse_lit, coarse_meto, fine_lit, fine_meto, fine_comp, ne_nested, nel_lit, nel_meto in zip(\n",
    "        sentences['tokens'], sentences['NE-COARSE-LIT'], sentences['NE-COARSE-METO'],\n",
    "        sentences['NE-FINE-LIT'], sentences['NE-FINE-METO'], sentences['NE-FINE-COMP'], sentences['NE-NESTED'],\n",
    "        sentences['NEL-LIT'], sentences['NEL-METO']\n",
    "    ):\n",
    "        for tags in [fine_lit, fine_meto, fine_comp, ne_nested]:\n",
    "            entities += get_entities(tokens, tags, nel_lit, nel_meto)\n",
    "\n",
    "    for entity in entities:\n",
    "        entity_type = entity['entity']\n",
    "        entity_name = entity['word']\n",
    "        unique_entity_types.add(entity_type)  # Track the entity type\n",
    "\n",
    "        function, name = None, None\n",
    "        if \"pers\" in entity_type:\n",
    "            function = get_detail(entity_name, entities, \"function\")\n",
    "            name = get_detail(entity_name, entities, \"name\")\n",
    "\n",
    "        entities_per_year[(entity_name, year, entity_type, function, name)] += 1\n",
    "        entities_per_decade[(entity_name, decade, entity_type, function, name)] += 1\n",
    "        entity_decade_appearances[entity_name].add(decade)\n",
    "        entity_year_appearances[entity_name].add(year)\n",
    "\n",
    "# Print statistics\n",
    "# print(\"Entities per year:\")\n",
    "# for (entity, year, entity_type, function, name), count in entities_per_year.items():\n",
    "#     print(f\"{entity} in {year} ({entity_type}, {function}, {name}): {count}\")\n",
    "\n",
    "# print(\"Entities per decade:\")\n",
    "# for (entity, decade, entity_type, function, name), count in entities_per_decade.items():\n",
    "#     print(f\"{entity} in {decade}s ({entity_type}, {function}, {name}): {count}\")\n",
    "\n",
    "# print(\"Entities mentioned in multiple decades:\")\n",
    "# for entity, decades in entity_decade_appearances.items():\n",
    "#     if len(decades) > 1:\n",
    "#         print(f\"{entity} appears in decades: {sorted(decades)}\")\n",
    "\n",
    "# print(\"Entities mentioned in multiple years:\")\n",
    "# for entity, years in entity_year_appearances.items():\n",
    "#     if len(years) > 1:\n",
    "#         print(f\"{entity} appears in years: {sorted(years)}\")\n",
    "\n",
    "# Print unique entity types\n",
    "print(\"Unique entity types:\")\n",
    "for entity_type in unique_entity_types:\n",
    "    print(entity_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa251e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entities mentioned in multiple years:\")\n",
    "for entity, years in entity_year_appearances.items():\n",
    "    if len(years) > 1:\n",
    "        entity = reglue_tokenized_text(entity.split())\n",
    "        print(f\"{entity} appears in years: {sorted(years)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f9715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter entities mentioned in multiple years and prepare data for plotting\n",
    "entity_year_counts = {}\n",
    "for (entity, year, entity_type, name, function), count in entities_per_year.items():\n",
    "    \n",
    "    if entity in entity_year_appearances and len(entity_year_appearances[entity]) > 1:\n",
    "        entity = reglue_tokenized_text(entity.split())\n",
    "        if len(entity) > 2:\n",
    "            if count > 5:\n",
    "                if entity not in entity_year_counts:\n",
    "                    entity_year_counts[entity] = {}\n",
    "                entity_year_counts[entity][year] = count\n",
    "\n",
    "# Plotting each entity's mentions per year\n",
    "plt.figure(figsize=(15, 10))\n",
    "for entity, year_counts in entity_year_counts.items():\n",
    "    years = sorted(year_counts.keys())\n",
    "    counts = [year_counts[year] for year in years]\n",
    "    plt.plot(years, counts, marker='o', label=entity)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Mentions')\n",
    "plt.title('Entities Mentioned in Multiple Years')\n",
    "plt.legend(title='Entities', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "for (entity, year, entity_type, name, function), count in entities_per_year.items():\n",
    "    if 'loc' in entity_type:\n",
    "        places.append(entity)\n",
    "        \n",
    "print(list(set(places)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "for (entity, year, entity_type, name, function), count in entities_per_year.items():\n",
    "    if 'pers' in entity_type:\n",
    "        persons.append((entity, year, entity_type, name, function))\n",
    "        \n",
    "for person in list(set(persons)):\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b4c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7079ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = client.get('Q70', load=True)\n",
    "correct_name = entity.data['labels']['fr']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d565cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                     | 0/158 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1226218 Ortafrontière --- 'fr'\n",
      "Could not decode Q5553647 Gessler --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▍                                                                                                                                                                    | 6/158 [04:03<1:28:06, 34.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q22389485 Signal --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████▊                                                                                                                                                               | 10/158 [06:00<1:26:18, 34.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q22386089 Molard --- 'fr'\n",
      "Could not decode Q22386089 Molard --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████████▊                                                                                                                                                              | 11/158 [07:18<1:57:52, 48.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q3646917 Gouille --- 'fr'\n",
      "Could not decode Q22532416 Sonmartel --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████████▉                                                                                                                                                             | 12/158 [07:28<1:28:46, 36.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q2543411 fabrique de peignes Walter S . A --- 'fr'\n",
      "Could not decode Q2543411 Walter S . A --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████████████▏                                                                                                                                                         | 15/158 [08:42<1:10:55, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q7400620 M . Sugimura , représentant du Japon --- 'fr'\n",
      "Could not decode Q7400620 M . --- 'fr'\n",
      "Could not decode Q7400620 Sugimura --- 'fr'\n",
      "Could not decode Q7400620 représentant du Japon --- 'fr'\n",
      "Could not decode Q7400620 Japon --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████████████▎                                                                                                                                                       | 17/158 [11:40<2:03:21, 52.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q6455769 L ' Indépendance roumaine --- 'fr'\n",
      "Could not decode Q7807661 Timpul --- 'fr'\n",
      "Could not decode Q518617 Reich --- 'fr'\n",
      "Could not decode Q518617 Reich --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████████████▉                                                                                                                                               | 25/158 [16:46<1:10:24, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q71715484 René BRXICHET --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████▌                                                                                                                                            | 29/158 [18:37<57:29, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q21480909 gouvernement despotique de Marcos - Perez Jimenez --- HTTP Error 404: Not Found\n",
      "Could not decode Q21480909 Marcos - Perez Jimenez --- HTTP Error 404: Not Found\n",
      "Could not decode Q21480909 gouvernement Perez Jimenez --- HTTP Error 404: Not Found\n",
      "Could not decode Q21480909 Perez Jimenez --- HTTP Error 404: Not Found\n",
      "Could not decode Q24904677 Radio - New - York --- 'fr'\n",
      "Could not decode Q24904677 New - York --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████████████▎                                                                                                                          | 44/158 [27:19<1:20:03, 42.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q56540279 Planckaert --- 'fr'\n",
      "Could not decode Q14849524 Bosberg --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████████▏                                                                                                | 68/158 [38:12<1:00:16, 40.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q692253 Wagram --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 74/158 [42:30<59:53, 42.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q56399581 Georges II --- 'fr'\n",
      "Could not decode Q56399581 Georges --- 'fr'\n",
      "Could not decode Q56399581 II --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████████████████████████████████████████████████████                                                                                    | 80/158 [47:59<1:31:32, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q22701451 dumontCenere --- 'fr'\n",
      "Could not decode Q22701451 dumontCenere --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 81/158 [50:00<1:49:47, 85.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q7736796 Globe --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                 | 82/158 [51:00<1:38:47, 78.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q3226542 tunnel du Hauenstein --- 'fr'\n",
      "Could not decode Q3226542 Hauenstein --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 88/158 [53:44<42:26, 36.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q22468133 Finstermunz --- 'fr'\n",
      "Could not decode Q22468133 Finstermunz --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 89/158 [55:45<1:10:58, 61.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q8077554 Tchataldja --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 94/158 [1:00:23<48:25, 45.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1196981 Sozialdemokrat --- 'fr'\n",
      "Could not decode Q15732510 Intelligenzblalt --- 'fr'\n",
      "Could not decode Q1196981 Sozialdemokral --- 'fr'\n",
      "Could not decode Q1196981 Sozialdemokrat --- 'fr'\n",
      "Could not decode Q1196981 Sozialdemokrat --- 'fr'\n",
      "Could not decode Q1196981 Sozutkkmokrat --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 96/158 [1:02:18<53:33, 51.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1807425 Club national libéral de Londres --- 'fr'\n",
      "Could not decode Q1807425 Londres --- 'fr'\n",
      "Could not decode Q7848267 Trulh --- 'fr'\n",
      "Could not decode Q5095721 Grand - Opéra --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 98/158 [1:06:12<1:18:09, 78.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q8527698 Fisistock --- 'fr'\n",
      "Could not decode Q1495421 vallée de Gastern --- 'fr'\n",
      "Could not decode Q1495421 Gastern --- 'fr'\n",
      "Could not decode Q15194031 Ausserberg --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                              | 99/158 [1:06:51<1:05:27, 66.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q60174481 Dovere --- 'fr'\n",
      "Could not decode Q1529377 Glasbrunnen --- 'fr'\n",
      "Could not decode Q29015698 col d ' Orsirora --- 'fr'\n",
      "Could not decode Q29015698 Orsirora --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 105/158 [1:11:30<33:11, 37.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q18628882 Lutzelmurg --- 'fr'\n",
      "Could not decode Q22702345 Wilhof --- 'fr'\n",
      "Could not decode Q18628882 Lù ! zel - Murg --- 'fr'\n",
      "Could not decode Q18628882 Lulzel - Murg --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 107/158 [1:12:30<28:47, 33.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q28112686 Deutsche Tageszeitung --- 'fr'\n",
      "Could not decode Q18028808 Tœgllche Rundschau --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 113/158 [1:16:07<23:39, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q13638293 Union internationale de secours aux enfants --- 'fr'\n",
      "Could not decode Q13638293 U --- 'fr'\n",
      "Could not decode Q13638293 I --- 'fr'\n",
      "Could not decode Q13638293 S . E . --- 'fr'\n",
      "Could not decode Q16524004 Dr Doxiadès , ancien ministre , président de la Ligue patriotique d ' assistance aux enfants --- 'fr'\n",
      "Could not decode Q13638293 U --- 'fr'\n",
      "Could not decode Q16524004 Dr --- 'fr'\n",
      "Could not decode Q16524004 Doxiadès --- 'fr'\n",
      "Could not decode Q16524004 ancien ministre --- 'fr'\n",
      "Could not decode Q16524004 président de la Ligue patriotique d ' assistance aux enfants --- 'fr'\n",
      "Could not decode Q16524004 Ligue patriotique d ' assistance aux enfants --- 'fr'\n",
      "Could not decode Q13638293 I --- 'fr'\n",
      "Could not decode Q13638293 S . E . --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 114/158 [1:16:22<19:39, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q13638293 Union internationale de secours aux enfants --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 117/158 [1:18:44<33:16, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q31975594 Dresde --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 118/158 [1:19:29<31:33, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q55367360 Christian ; Kaufmann --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 121/158 [1:22:35<33:07, 53.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1562949 H --- 'fr'\n",
      "Could not decode Q1562949 C . Olten --- 'fr'\n",
      "Could not decode Q1562949 Olten --- 'fr'\n",
      "Could not decode Q2679675 Stade Lausanwe --- 'fr'\n",
      "Could not decode Q2679675 Lausanwe --- 'fr'\n",
      "Could not decode Q2679675 Stade Lausanne --- 'fr'\n",
      "Could not decode Q2679675 Lausanne --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q2679675 Stade Lausanne --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q2679675 Stade --- 'fr'\n",
      "Could not decode Q28231423 Urania --- 'fr'\n",
      "Could not decode Q2679675 Stade Lausanne --- 'fr'\n",
      "Could not decode Q2679675 Lausanne --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 123/158 [1:24:42<35:05, 60.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1632773 L ' Aixmt - Garde --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 127/158 [1:25:45<13:11, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q27924254 Znamia --- 'fr'\n",
      "Could not decode Q21641201 Literatournaïa Moskva --- 'fr'\n",
      "Could not decode Q21641201 Moskva --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 138/158 [1:30:53<08:02, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q14214519 partie orientale du Cambodge --- 'fr'\n",
      "Could not decode Q14214519 Cambodge --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 139/158 [1:32:03<12:00, 37.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q28101962 Mundschin --- 'fr'\n",
      "Could not decode Q28101962 Mundschin --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 143/158 [1:34:42<08:00, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q14685139 Vail --- 'fr'\n",
      "Could not decode Q14685139 Vail --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 144/158 [1:35:03<06:43, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q1566819 Infranor --- 'fr'\n",
      "Could not decode Q682685 BSI --- 'fr'\n",
      "Could not decode Q2526106 Villars --- 'fr'\n",
      "Could not decode Q30273339 Œrlikon Buchrle --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 145/158 [1:36:42<10:46, 49.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode Q32066354 Kobel --- 'fr'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 158/158 [1:40:25<00:00, 38.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming dataset and get_entities are already defined\n",
    "\n",
    "# List to collect all the row data\n",
    "data = []\n",
    "\n",
    "for document in tqdm(dataset['train'], total=len(dataset['train'])):\n",
    "    metadata = ast.literal_eval(document['metadata'])\n",
    "    date = metadata.get('date')\n",
    "    source = metadata.get('publication_title')\n",
    "    language = metadata.get('language')\n",
    "    doc_type = metadata.get('document_type')\n",
    "\n",
    "    if not date:\n",
    "        continue  # Skip documents without a date\n",
    "\n",
    "    year = int(date[:4])\n",
    "    decade = year - (year % 10)\n",
    "    sentences_data = document['sentences']\n",
    "    article_text = \" \".join([\" \".join(sentence) for sentence in sentences_data['tokens']])  # Concatenate all sentences\n",
    "\n",
    "    for tokens, coarse_lit, coarse_meto, fine_lit, fine_meto, fine_comp, ne_nested, nel_lit, nel_meto in zip(\n",
    "        sentences_data['tokens'], sentences_data['NE-COARSE-LIT'], sentences_data['NE-COARSE-METO'],\n",
    "        sentences_data['NE-FINE-LIT'], sentences_data['NE-FINE-METO'], sentences_data['NE-FINE-COMP'], sentences_data['NE-NESTED'],\n",
    "        sentences_data['NEL-LIT'], sentences_data['NEL-METO']\n",
    "    ):\n",
    "        sentence_text = \" \".join(tokens)\n",
    "        entities = []\n",
    "        for tags in [fine_lit, fine_meto, fine_comp, ne_nested]:\n",
    "            entities += get_entities(tokens, tags, nel_lit, nel_meto)\n",
    "\n",
    "        # Append data for each sentence in the document\n",
    "        data.append({\n",
    "            'date': date,\n",
    "            'source': source,\n",
    "            'language': language,\n",
    "            'doc_type': doc_type,\n",
    "            'year': year,\n",
    "            'decade': decade,\n",
    "            'sentence': sentence_text,\n",
    "            'entities': entities,\n",
    "            'article': article_text\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f7db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../world-models/data/entity_datasets/hipe-fr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1412c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "      <td>[{'index': 3, 'entity': 'time.date.abs', 'word...</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Environ 30,000 fr . ont été versés dans la cai...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Ecoles de fonctionnaires</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>— On parle de fonder deux facultés de sciences...</td>\n",
       "      <td>[{'index': 15, 'entity': 'loc.adm.town', 'word...</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Chemins de fer</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quelques courts ex - traits un peu au hasard</td>\n",
       "      <td>[]</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>A l ’ entrée en Bulgarie : « La douane se pass...</td>\n",
       "      <td>[{'index': 5, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Sur un bateau au large de Bahreïn : « Les port...</td>\n",
       "      <td>[{'index': 6, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Impossible de leur faire comprendre qu ’ en Eu...</td>\n",
       "      <td>[{'index': 8, 'entity': 'loc.adm.sup', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>» Chez le médecin en Inde : « Il y a un dispen...</td>\n",
       "      <td>[{'index': 5, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5679 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date source language   doc_type  year  decade  \\\n",
       "0     1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "1     1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "2     1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "3     1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "4     1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "...          ...    ...      ...        ...   ...     ...   \n",
       "5674  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5675  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5676  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5677  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5678  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     NOUVELLES SUISSES — En 1887 , la Société suiss...   \n",
       "1     Environ 30,000 fr . ont été versés dans la cai...   \n",
       "2                              Ecoles de fonctionnaires   \n",
       "3     — On parle de fonder deux facultés de sciences...   \n",
       "4                                        Chemins de fer   \n",
       "...                                                 ...   \n",
       "5674       Quelques courts ex - traits un peu au hasard   \n",
       "5675  A l ’ entrée en Bulgarie : « La douane se pass...   \n",
       "5676  Sur un bateau au large de Bahreïn : « Les port...   \n",
       "5677  Impossible de leur faire comprendre qu ’ en Eu...   \n",
       "5678  » Chez le médecin en Inde : « Il y a un dispen...   \n",
       "\n",
       "                                               entities  \\\n",
       "0     [{'index': 3, 'entity': 'time.date.abs', 'word...   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3     [{'index': 15, 'entity': 'loc.adm.town', 'word...   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "5674                                                 []   \n",
       "5675  [{'index': 5, 'entity': 'loc.adm.nat', 'word':...   \n",
       "5676  [{'index': 6, 'entity': 'loc.adm.nat', 'word':...   \n",
       "5677  [{'index': 8, 'entity': 'loc.adm.sup', 'word':...   \n",
       "5678  [{'index': 5, 'entity': 'loc.adm.nat', 'word':...   \n",
       "\n",
       "                                                article  \n",
       "0     NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "1     NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "2     NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "3     NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "4     NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "...                                                 ...  \n",
       "5674  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5675  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5676  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5677  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5678  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "\n",
       "[5679 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a609aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 3, 'entity': 'time.date.abs', 'word': 'En 1887'},\n",
       " {'index': 7,\n",
       "  'entity': 'org.ent',\n",
       "  'word': 'Société suisse du Grutli',\n",
       "  'qid': 'Q683672',\n",
       "  'wikipedia': 'Société du Grütli'},\n",
       " {'index': 10,\n",
       "  'entity': 'loc.phys.geo',\n",
       "  'word': 'Grutli',\n",
       "  'qid': 'Q683672',\n",
       "  'wikipedia': 'Société du Grütli'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c76bd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'» Chez le médecin en Inde : « Il y a un dispensaire , avec un toubib indigène , genre charlatan , nous y amenons « Scipion » ; il fait une ordonnance en hindou , la passe à son pharmacien assis un peu plus loin entouré de flacons de poudres de toutes les couleurs ( . . . ) »'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-1].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71f05cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "def get_historical_events(year, month, day, language):\n",
    "    # Initialize the Wikipedia API with the English language\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('HistoricalEvents (emanuela.boros@gmail.com)', language)\n",
    "    \n",
    "    # Construct the page title in the format \"Month Day\"\n",
    "    date = f\"{month} {day}\"\n",
    "    \n",
    "    # Try to get the Wikipedia page for the given date\n",
    "    page = wiki_wiki.page(date)\n",
    "    \n",
    "    if not page.exists():\n",
    "        return \"No page found for this date.\"\n",
    "    \n",
    "    # Extract the content of the page\n",
    "    text = page.text\n",
    "    \n",
    "    # Split the text into lines and filter for the specific year\n",
    "    events = [line for line in text.split('\\n') if line.startswith(str(year))]\n",
    "    \n",
    "    return events if events else \"No historical events found for this date.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6450882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1969 – Apollo program: Apollo 11's crew successfully makes the first human landing on the Moon in the Sea of Tranquility. Americans Neil Armstrong and Buzz Aldrin become the first humans to walk on the Moon six and a half hours later.\", '1969   – A cease fire is announced between Honduras and El Salvador, six days after the beginning of the \"Football War\".', '1969 – Josh Holloway, American actor', '1969   – Kreso Kovacec, Croatian-German footballer', '1969   – Giovanni Lombardi, Italian cyclist', '1969   – Joon Park, South Korean-American singer', '1969   – Tobi Vail, American singer and guitarist', '1969   – Vitamin C, American singer-songwriter']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "year = 1969\n",
    "month = \"July\"\n",
    "day = 20\n",
    "events = get_historical_events(year, month, day)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e03591ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Events on 9 January:\n",
      "No historical events found for this date.\n",
      "French Events on 9 Janvier:\n",
      "No historical events found for this date.\n",
      "German Events on 9. Januar:\n",
      "No historical events found for this date.\n",
      "English Events on 21 January:\n",
      "['1908 – New York City passes the Sullivan Ordinance, making it illegal for women to smoke in public, only to have the measure vetoed by the mayor.']\n",
      "French Events on 21 Janvier:\n",
      "No historical events found for this date.\n",
      "German Events on 21. Januar:\n",
      "['1908: In Stockholm findet die Uraufführung des Kammerspiels Die Gespenstersonate von August Strindberg nach der gleichnamigen Sonate von Ludwig van Beethoven statt. Die Uraufführung floppt, das Stück wird erst vier Jahre nach dem Tod des Dichters ein Erfolg.', '1908: Am Theater an der Wien in Wien erfolgt die Uraufführung der Operette Der Mann mit den drei Frauen von Franz Lehár.', '1908: Raymond D. Gary, US-amerikanischer Politiker', '1908: Louise Rosenbaum, US-amerikanische Mathematikerin und Hochschullehrerin', '1908: Bengt Strömgren, dänischer Astronom']\n",
      "English Events on 31 January:\n",
      "No historical events found for this date.\n",
      "French Events on 31 Janvier:\n",
      "['1908 :']\n",
      "German Events on 31. Januar:\n",
      "['1908: Bill Cantrell, US-amerikanischer Automobilrennfahrer', '1908: Atahualpa Yupanqui, argentinischer Sänger, Songwriter, Gitarrist und Schriftsteller']\n",
      "English Events on 15 May:\n",
      "No historical events found for this date.\n",
      "French Events on 15 Mai:\n",
      "No historical events found for this date.\n",
      "German Events on 15. Mai:\n",
      "['1908: Erich Bielka, österreichischer Diplomat1908: Emil Joseph Diemer, deutscher Schachspieler', '1908: Joe Grant, US-amerikanischer Comic-Autor', '1908: Albert Heinrich Kniest, deutscher Schachproblem-Komponist', '1908: Lars-Erik Larsson, schwedischer Komponist']\n",
      "English Events on 13 August:\n",
      "['1908 – Gene Raymond, American actor and pilot (d. 1998)']\n",
      "French Events on 13 Août:\n",
      "No historical events found for this date.\n",
      "German Events on 13. August:\n",
      "['1908: Willi Beuster, deutscher Politiker, MdB', '1908: Kläre Bloch, deutsche Taxifahrerin und Fluchthelferin für NS-Verfolgte', '1908: Ira D. Sankey, US-amerikanischer Sänger und Komponist von Erweckungsliedern']\n",
      "English Events on 21 January:\n",
      "['1918 – Jimmy Hagan, English footballer (d. 1998)', '1918   – Antonio Janigro, Italian cellist and conductor (d. 1989)', '1918   – Richard Winters, American soldier (d. 2011)', '1918 – Jan Drozdowski, Polish pianist and music teacher (b. 1857)']\n",
      "French Events on 21 Janvier:\n",
      "['1918 : Richard Davis Winters, militaire américain († 2 janvier 2011).']\n",
      "German Events on 21. Januar:\n",
      "['1918: Antonio Janigro, italienischer Cellist, Dirigent und Hochschullehrer', '1918: Richard Winters, US-amerikanischer Offizier', '1918: Jan Drozdowski, polnischer Pianist und Musikpädagoge', '1918: Emil Jellinek, deutscher Geschäftsmann und Konsul', '1918: Anna Maria Petersen, deutsche Malerin']\n",
      "English Events on 12 February:\n",
      "['1918 – Norman Farberow, American psychologist and academic (d. 2015)', '1918   – Julian Schwinger, American physicist and academic, Nobel Prize laureate (d. 1994)']\n",
      "French Events on 12 Février:\n",
      "['1918 : Julian Schwinger, physicien américain, lauréat du prix Nobel de physique en 1965 († 16 juillet 1994).']\n",
      "German Events on 12. Februar:\n",
      "['1918: Franz Leitner, österreichischer Politiker, Gerechter unter den Völkern', '1918: Julian Seymour Schwinger, US-amerikanischer Physiker', '1918: Viktor Böhmert, deutscher Journalist, Freihändler und Volkswirt']\n",
      "English Events on 22 April:\n",
      "['1918 – William Jay Smith, American poet and academic (d. 2015)', '1918   – Mickey Vernon, American baseball player and coach (d. 2008)']\n",
      "French Events on 22 Avril:\n",
      "['1918 : Mickey Vernon (en), joueur et gestionnaire de baseball américain († 24 septembre 2008).']\n",
      "German Events on 22. April:\n",
      "['1918: Solomon Aaron Berson, US-amerikanischer Mediziner', '1918: Carl Reuß, deutscher Forstmann']\n",
      "English Events on 8 June:\n",
      "['1918 – A solar eclipse is observed at Baker City, Oregon by scientists and an artist hired by the United States Navy.', '1918 – George Edward Hughes, Irish-New Zealand philosopher and logician (d. 1994)', '1918   – Robert Preston, American actor and singer (d. 1987)', '1918   – John D. Roberts, American chemist and academic (d. 2016)']\n",
      "French Events on 8 Juin:\n",
      "['1918 :']\n",
      "German Events on 8. Juni:\n",
      "['1918: Gunther Philipp, österreichischer Schauspieler', '1918: Robert Preston, US-amerikanischer Schauspieler', '1918: Franz Fischer, deutscher Dirigent und Cellist']\n",
      "English Events on 10 July:\n",
      "['1918 – James Aldridge, Australian-English journalist and author (d. 2015)', '1918   – Chuck Stevens, American baseball player (d. 2018)', '1918   – Frank L. Lambert, Professor Emeritus of Chemistry at Occidental College (d. 2018)', '1918   – Fred Wacker, American race driver and engineer (d. 1998)']\n",
      "French Events on 10 Juillet:\n",
      "No historical events found for this date.\n",
      "German Events on 10. Juli:\n",
      "['1918: Johannes Oppenheimer, deutscher Jurist, Vizepräsident des Bundesverwaltungsgerichtes', '1918: Fred Wacker, US-amerikanischer Autorennfahrer']\n",
      "English Events on 18 November:\n",
      "['1918 – Latvia declares its independence from Russia.', '1918 – İlhan Berk, Turkish poet and author (d. 2008)', '1918   – Tasker Watkins, Welsh soldier, judge, and politician, Victoria Cross recipient (d. 2007)']\n",
      "French Events on 18 Novembre:\n",
      "[\"1918 : proclamation de l'indépendance de la Lettonie.\"]\n",
      "German Events on 18. November:\n",
      "['1918: Der Lettische Volksrat ruft die Unabhängigkeit Lettlands aus.']\n",
      "English Events on 17 January:\n",
      "['1928 – Jean Barraqué, French composer (d. 1973)', '1928   – Vidal Sassoon, English-American hairdresser and businessman (d. 2012)']\n",
      "French Events on 17 Janvier:\n",
      "['1928 :']\n",
      "German Events on 17. Januar:\n",
      "['1928: Jean Barraqué, französischer Komponist', '1928: Roman Frister, polnisch-israelischer Journalist und Schriftsteller', '1928: Benno Meyer-Wehlack, deutscher Schriftsteller', '1928: Vidal Sassoon, britischer Friseur und Unternehmer']\n",
      "English Events on 18 April:\n",
      "['1928 – Karl Josef Becker, German cardinal and theologian (d. 2015)', '1928   – Otto Piene, German sculptor and academic (d. 2014)']\n",
      "French Events on 18 Avril:\n",
      "['1928 : Howard Becker, sociologue américain.']\n",
      "German Events on 18. April:\n",
      "['1928: Ken Colyer, britischer Jazzkornettist', '1928: Heinz Lieven, deutscher Schauspieler', '1928: Otto Piene, deutscher Künstler', '1928: Jürgen Seifert, deutscher Politikwissenschaftler und Bürgerrechtler', '1928; Henryk Melcer-Szczawiński, polnischer Pianist, Dirigent, Komponist und Musikpädagoge']\n",
      "English Events on 21 September:\n",
      "No historical events found for this date.\n",
      "French Events on 21 Septembre:\n",
      "['1928 : Édouard Glissant, écrivain, poète et essayiste français († 3 février 2011).']\n",
      "German Events on 21. September:\n",
      "['1928: Édouard Glissant, französischer Schriftsteller, Dichter und Philosoph', '1928: Josef Strauß, deutscher Fußballspieler']\n",
      "English Events on 25 October:\n",
      "['1928 – Jeanne Cooper, American actress (d. 2013)', '1928   – Paulo Mendes da Rocha, Brazilian architect (d. 2021)', '1928   – Anthony Franciosa, American actor (d. 2006)', '1928   – Adolphe Gesché, Belgian Catholic priest and theologian (d. 2003)', '1928   – Peter Naur, Danish computer scientist, astronomer, and academic (d. 2016)', '1928   – Marion Ross, American actress', '1928   – Yakov Rylsky, Soviet sabre fencer (d. 1999)']\n",
      "French Events on 25 Octobre:\n",
      "['1928 :']\n",
      "German Events on 25. Oktober:\n",
      "['1928: Wolfgang Eger, deutscher Historiker und Autor', '1928: Essien Udosen Essien-Udom, nigerianischer Politologe und Soziologe', '1928: Peter Naur, dänischer Informatiker', '1928: Hirotsu Ryūrō, japanischer Schriftsteller']\n",
      "English Events on 19 December:\n",
      "['1928 – Eve Bunting, Irish-American author and academic (d. 2023)', '1928   – Nathan Oliveira, American painter and sculptor (d. 2010)']\n",
      "French Events on 19 Décembre:\n",
      "No historical events found for this date.\n",
      "German Events on 19. Dezember:\n",
      "['1928: Nikolaus Arndt, deutscher Architekt, Historiker und Kommunalpolitiker', '1928: Herbert Bötticher, deutscher Schauspieler']\n",
      "English Events on 1 April:\n",
      "No historical events found for this date.\n",
      "French Events on 1 Avril:\n",
      "['1938 : invention du Nescafé.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Events on 1. April:\n",
      "['1938: In der Schweiz wird erstmals der von Nestlé hergestellte Instantkaffee Nescafé verkauft.', '1938: Erich Müller, Schweizer Industriemanager und Politiker', '1938: Ingrid Spors, deutsche Politikerin', '1938: Richard Du Moulin-Eckart, deutscher Historiker', '1938: Rafaela Serrano Rodríguez, kubanische Pianistin und Musikpädagogin spanischer Herkunft']\n",
      "English Events on 11 May:\n",
      "['1938 – Narendra Patel, Baron Patel, Tanzanian-English obstetrician, academic, and politician', '1938 – George Lyon, Canadian golfer and cricketer (b. 1858)']\n",
      "French Events on 11 Mai:\n",
      "['1938 : début de la construction du canal Rhin-Main-Danube.']\n",
      "German Events on 11. Mai:\n",
      "['1938: Sig Ohlemann, kanadischer Mittelstreckenläufer und Sprinter', '1938: Friedrich Eckenfelder, deutscher Maler', '1938: Jewgeni Karlowitsch Miller, General im Russischen Bürgerkrieg', '1938: Friedrich Knutzen, deutscher Politiker']\n",
      "English Events on 21 June:\n",
      "['1938 – Don Black, English songwriter', '1938   – John W. Dower, American historian and author', '1938   – Michael M. Richter, German mathematician and computer scientist (d. 2020)']\n",
      "French Events on 21 Juin:\n",
      "['1938 : Ron Ely, acteur américain.']\n",
      "German Events on 21. Juni:\n",
      "['1938: Ron Ely, US-amerikanischer Schauspieler', '1938ː Gertrud Staats, deutsche Malerin1940: Walter Hasenclever, deutscher Schriftsteller des Expressionismus']\n",
      "English Events on 8 September:\n",
      "['1938 – Adrian Cronauer, American sergeant and radio host (d. 2018)', '1938   – Kenichi Horie, Japanese sailor', '1938   – Sam Nunn, American lawyer and politician']\n",
      "French Events on 8 Septembre:\n",
      "['1938 :']\n",
      "German Events on 8. September:\n",
      "['1938: Wolfgang Bötsch, deutscher Politiker, MdL, MdB, Bundespostminister', '1938: Wibke Bruhns, deutsche Journalistin', '1938: Alfons Maria Augner, Schweizer Benediktinermönch']\n",
      "English Events on 27 September:\n",
      "['1938 – The ocean liner Queen Elizabeth is launched in Glasgow.', '1938 – Jean-Loup Dabadie, French journalist, songwriter, and screenwriter (d. 2020)']\n",
      "French Events on 27 Septembre:\n",
      "['1938 :']\n",
      "German Events on 27. September:\n",
      "['1938: In der Fünften Verordnung zum Reichsbürgergesetz wird während der Zeit des Nationalsozialismus jüdischen Rechtsanwälten die Zulassung ab 30. November 1938 entzogen. Das bereits restriktive Gesetz über die Zulassung zur Rechtsanwaltschaft von 1933 hatte ihnen in Deutschland noch begrenzt die Berufsausübung gestattet.', '1938: Das mehr als ein halbes Jahrhundert weltweit größte Passagierschiff, die Queen Elizabeth, absolviert seinen Stapellauf.', '1938: Günter Brus, österreichischer Aktionskünstler und Maler', '1938: Sharifa Fadel, ägyptische Schauspielerin und Sängerin', '1938: Alberto Orlando, italienischer Fußballspieler', '1938: Klaus Völker, deutscher Theaterhistoriker']\n",
      "English Events on 24 December:\n",
      "['1938 – Bobby Henrich, American baseball player', '1938   – Valentim Loureiro, Portuguese soldier and politician', '1938 – Bruno Taut, German architect and urban planner (b. 1880)']\n",
      "French Events on 24 Décembre:\n",
      "['1938 :']\n",
      "German Events on 24. Dezember:\n",
      "['1938: Hartmuth Arenhövel, deutscher theoretischer Kernphysiker', '1938: Hans Küppers, deutscher Fußballspieler', '1938: Mesías Maiguashca, ecuadorianischer Komponist', '1938: Carl Miele, deutscher Konstrukteur und Industrieller', '1938: Bruno Taut, deutscher Architekt und Stadtplaner']\n",
      "English Events on 23 February:\n",
      "['1948 – Bill Alexander, English director and producer', '1948   – Trevor Cherry, English footballer (d. 2020)', '1948   – Steve Priest, English singer-songwriter and bass player (d. 2020)', '1948 – John Robert Gregg, Irish-American publisher and educator (b. 1866)']\n",
      "French Events on 23 Février:\n",
      "['1948 :', '1948 : Edmond André Rocher, poète, écrivain et plasticien français (° 2 novembre 1873).']\n",
      "German Events on 23. Februar:\n",
      "['1948: In London beginnt die bis zum 6. Juni dauernde Sechsmächtekonferenz der drei westlichen Besatzungsmächte und der direkt an Westdeutschland angrenzenden Benelux-Staaten mit dem Ziel, die Grundlage für die Beteiligung eines demokratischen Deutschlands an der Völkergemeinschaft zu schaffen. Als Folge der Konferenz stellte die Sowjetunion ihre Mitarbeit im Alliierten Kontrollrat ein.', '1948: Steve Priest, britischer Bassist (The Sweet)', '1948: Waltraud Roick, deutsche Ruderin', '1948: Fidus, deutscher Maler und Illustrator', '1948: Arthur Grimm, deutscher Maler', '1948: Hermann Weber, deutscher Motorradkonstrukteur und -rennfahrer']\n",
      "English Events on 17 March:\n",
      "['1948 – Belgium, France, Luxembourg, the Netherlands and the United Kingdom sign the Treaty of Brussels, a precursor to the North Atlantic Treaty establishing NATO.', '1948 – William Gibson, American-Canadian author and screenwriter', '1948   – Alex MacDonald, Scottish footballer and manager']\n",
      "French Events on 17 Mars:\n",
      "[\"1948 : la France, le Royaume-Uni et les pays du Benelux signent le traité de Bruxelles, un précurseur de l'OTAN.\", '1948 :']\n",
      "German Events on 17. März:\n",
      "['1948: Der Brüsseler Pakt als Vorläufer der Westeuropäischen Union (WEU) wird von Großbritannien, Frankreich, Belgien, den Niederlanden und Luxemburg unterzeichnet.', '1948: William Gibson, US-amerikanischer Science-Fiction-Autor', '1948: Martin Mönikes, deutscher Journalist und Politiker', '1948: Jessica Williams, US-amerikanische Jazzpianistin']\n",
      "English Events on 29 May:\n",
      "['1948 – United Nations Truce Supervision Organization is founded.', '1948 – Michael Berkeley, English composer and radio host', '1948   – Keith Gull, English microbiologist and academic', '1948 – May Whitty, English actress (b. 1865)']\n",
      "French Events on 29 Mai:\n",
      "['1948 : résolution no 50 du Conseil de sécurité des Nations unies, sur la question palestinienne.', '1948 : Jean Legrez, prélat français.']\n",
      "German Events on 29. Mai:\n",
      "['1948: Michael Berkeley, britischer Komponist', '1948: Nick Mancuso, kanadischer Schauspieler1948: Peter Paziorek, deutscher Basketballspieler und Politiker, MdB, Parlamentarischer Staatssekretär, Regierungspräsident von Münster', '1948: Günter Sebert, deutscher Fußballspieler', '1948: May Whitty, britische Schauspielerin']\n",
      "English Events on 11 September:\n",
      "['1948 – John Martyn, English-Scottish singer-songwriter and guitarist (d. 2009)', '1948 – Muhammad Ali Jinnah, Pakistani lawyer and politician, 1st Governor-General of Pakistan (b. 1876)']\n",
      "French Events on 11 Septembre:\n",
      "No historical events found for this date.\n",
      "German Events on 11. September:\n",
      "['1948: Maria Eichhorn, deutsche Politikerin, MdB', '1948: John Martyn, britischer Musiker, Sänger und Songschreiber', '1948: Muhammad Ali Jinnah, pakistanischer Staatsgründer und -präsident']\n",
      "English Events on 16 September:\n",
      "['1948 – Ron Blair, American bass player', '1948   – Rosemary Casals, American tennis player and sportscaster', '1948   – Julia Donaldson, English author and playwright', '1948   – Kenney Jones, English drummer', '1948   – Susan Ruttan, American actress']\n",
      "French Events on 16 Septembre:\n",
      "['1948 :']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Handle German\u001b[39;00m\n\u001b[1;32m     61\u001b[0m month_de \u001b[38;5;241m=\u001b[39m month_map_de[month]\n\u001b[0;32m---> 62\u001b[0m events_de \u001b[38;5;241m=\u001b[39m \u001b[43mget_historical_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth_de\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mde\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGerman Events on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth_de\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(events_de)\n",
      "Cell \u001b[0;32mIn[54], line 18\u001b[0m, in \u001b[0;36mget_historical_events\u001b[0;34m(year, month, day, lang)\u001b[0m\n\u001b[1;32m     15\u001b[0m     date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Month first for English\u001b[39;00m\n\u001b[1;32m     17\u001b[0m page \u001b[38;5;241m=\u001b[39m wiki_wiki\u001b[38;5;241m.\u001b[39mpage(date)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo page found for this date in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikipediaapi/__init__.py:910\u001b[0m, in \u001b[0;36mWikipediaPage.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    905\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m    Returns `True` if the current page exists, otherwise `False`.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    :return: if current page existst or not\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpageid\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikipediaapi/__init__.py:874\u001b[0m, in \u001b[0;36mWikipediaPage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mATTRIBUTES_MAPPING[name]:\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_called[call]:\n\u001b[0;32m--> 874\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attributes[name]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikipediaapi/__init__.py:1064\u001b[0m, in \u001b[0;36mWikipediaPage._fetch\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, call) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWikipediaPage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fetches some data?.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwiki\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_called[call] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikipediaapi/__init__.py:332\u001b[0m, in \u001b[0;36mWikipedia.info\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03mhttps://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mhttps://www.mediawiki.org/wiki/API:Info\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     ),\n\u001b[1;32m    331\u001b[0m }\n\u001b[0;32m--> 332\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_attributes(raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m], page)\n\u001b[1;32m    334\u001b[0m pages \u001b[38;5;241m=\u001b[39m raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/wikipediaapi/__init__.py:528\u001b[0m, in \u001b[0;36mWikipedia._query\u001b[0;34m(self, page, params)\u001b[0m\n\u001b[1;32m    526\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredirects\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 528\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1061\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1062\u001b[0m         (\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_default_certs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    436\u001b[0m     default_ssl_context\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mversion() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    440\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1038\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wikipediaapi\n",
    "from datetime import datetime\n",
    "\n",
    "# Wikipedia API setup with language support\n",
    "def get_historical_events(year, month, day, lang='en'):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('HistoricalEvents (emanuela.boros@gmail.com)', lang)\n",
    "    \n",
    "    # Ensure correct date format for French and German\n",
    "    if lang == 'fr':\n",
    "        date = f\"{day} {month.lower()}\"  # Day first, month lowercase\n",
    "    elif lang == 'de':\n",
    "        date = f\"{day}. {month}\"  # Day followed by a period\n",
    "    else:\n",
    "        date = f\"{month} {day}\"  # Month first for English\n",
    "    \n",
    "    page = wiki_wiki.page(date)\n",
    "    if not page.exists():\n",
    "        return f\"No page found for this date in {lang}.\"\n",
    "    \n",
    "    text = page.text\n",
    "    events = [line for line in text.split('\\n') if line.startswith(str(year))]\n",
    "    return events if events else \"No historical events found for this date.\"\n",
    "\n",
    "# Maps for translating English month names to French and German\n",
    "month_map_fr = {\n",
    "    'January': 'Janvier', 'February': 'Février', 'March': 'Mars',\n",
    "    'April': 'Avril', 'May': 'Mai', 'June': 'Juin',\n",
    "    'July': 'Juillet', 'August': 'Août', 'September': 'Septembre',\n",
    "    'October': 'Octobre', 'November': 'Novembre', 'December': 'Décembre'\n",
    "}\n",
    "month_map_de = {\n",
    "    'January': 'Januar', 'February': 'Februar', 'March': 'März',\n",
    "    'April': 'April', 'May': 'Mai', 'June': 'Juni',\n",
    "    'July': 'Juli', 'August': 'August', 'September': 'September',\n",
    "    'October': 'Oktober', 'November': 'November', 'December': 'Dezember'\n",
    "}\n",
    "\n",
    "# Iterate over DataFrame\n",
    "dates = []\n",
    "for _, item in df.iterrows():\n",
    "    if item.date not in dates:\n",
    "        dates.append(item.date)\n",
    "        date_obj = datetime.strptime(item.date, '%Y-%m-%d')\n",
    "        year = date_obj.year\n",
    "        month = date_obj.strftime('%B')\n",
    "        day = date_obj.day\n",
    "\n",
    "        # Handle English\n",
    "        events_en = get_historical_events(year, month, day, lang='en')\n",
    "        print(f\"English Events on {day} {month}:\")\n",
    "        print(events_en)\n",
    "        \n",
    "        # Handle French\n",
    "        month_fr = month_map_fr[month]\n",
    "        events_fr = get_historical_events(year, month_fr, day, lang='fr')\n",
    "        print(f\"French Events on {day} {month_fr}:\")\n",
    "        print(events_fr)\n",
    "\n",
    "        # Handle German\n",
    "        month_de = month_map_de[month]\n",
    "        events_de = get_historical_events(year, month_de, day, lang='de')\n",
    "        print(f\"German Events on {day}. {month_de}:\")\n",
    "        print(events_de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbb5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f707f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48788e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e4711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f72371dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 5, 'entity': 'loc.adm.nat', 'word': 'Inde', 'qid': 'Q668'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8575ec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "      <td>[{'index': 3, 'entity': 'time.date.abs', 'word...</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Environ 30,000 fr . ont été versés dans la cai...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Ecoles de fonctionnaires</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>— On parle de fonder deux facultés de sciences...</td>\n",
       "      <td>[{'index': 15, 'entity': 'loc.adm.town', 'word...</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1888-01-09</td>\n",
       "      <td>EXP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>1888</td>\n",
       "      <td>1880</td>\n",
       "      <td>Chemins de fer</td>\n",
       "      <td>[]</td>\n",
       "      <td>NOUVELLES SUISSES — En 1887 , la Société suiss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date source language   doc_type  year  decade  \\\n",
       "0  1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "1  1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "2  1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "3  1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "4  1888-01-09    EXP       fr  newspaper  1888    1880   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  NOUVELLES SUISSES — En 1887 , la Société suiss...   \n",
       "1  Environ 30,000 fr . ont été versés dans la cai...   \n",
       "2                           Ecoles de fonctionnaires   \n",
       "3  — On parle de fonder deux facultés de sciences...   \n",
       "4                                     Chemins de fer   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [{'index': 3, 'entity': 'time.date.abs', 'word...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [{'index': 15, 'entity': 'loc.adm.town', 'word...   \n",
       "4                                                 []   \n",
       "\n",
       "                                             article  \n",
       "0  NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "1  NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "2  NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "3  NOUVELLES SUISSES — En 1887 , la Société suiss...  \n",
       "4  NOUVELLES SUISSES — En 1887 , la Société suiss...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e7e0d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 3, 'entity': 'time.date.abs', 'word': 'En 1887'},\n",
       " {'index': 7, 'entity': 'org.ent', 'word': 'Société suisse du Grutli'},\n",
       " {'index': 10, 'entity': 'loc.phys.geo', 'word': 'Grutli'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c271c5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quelques courts ex - traits un peu au hasard</td>\n",
       "      <td>[]</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>A l ’ entrée en Bulgarie : « La douane se pass...</td>\n",
       "      <td>[{'index': 5, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Sur un bateau au large de Bahreïn : « Les port...</td>\n",
       "      <td>[{'index': 6, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>Impossible de leur faire comprendre qu ’ en Eu...</td>\n",
       "      <td>[{'index': 8, 'entity': 'loc.adm.sup', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>IMP</td>\n",
       "      <td>fr</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010</td>\n",
       "      <td>» Chez le médecin en Inde : « Il y a un dispen...</td>\n",
       "      <td>[{'index': 5, 'entity': 'loc.adm.nat', 'word':...</td>\n",
       "      <td>COURTS EXTRAITS Le carnet de bord des quatre b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date source language   doc_type  year  decade  \\\n",
       "5674  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5675  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5676  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5677  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "5678  2018-01-03    IMP       fr  newspaper  2018    2010   \n",
       "\n",
       "                                               sentence  \\\n",
       "5674       Quelques courts ex - traits un peu au hasard   \n",
       "5675  A l ’ entrée en Bulgarie : « La douane se pass...   \n",
       "5676  Sur un bateau au large de Bahreïn : « Les port...   \n",
       "5677  Impossible de leur faire comprendre qu ’ en Eu...   \n",
       "5678  » Chez le médecin en Inde : « Il y a un dispen...   \n",
       "\n",
       "                                               entities  \\\n",
       "5674                                                 []   \n",
       "5675  [{'index': 5, 'entity': 'loc.adm.nat', 'word':...   \n",
       "5676  [{'index': 6, 'entity': 'loc.adm.nat', 'word':...   \n",
       "5677  [{'index': 8, 'entity': 'loc.adm.sup', 'word':...   \n",
       "5678  [{'index': 5, 'entity': 'loc.adm.nat', 'word':...   \n",
       "\n",
       "                                                article  \n",
       "5674  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5675  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5676  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5677  COURTS EXTRAITS Le carnet de bord des quatre b...  \n",
       "5678  COURTS EXTRAITS Le carnet de bord des quatre b...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04772c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in world_models/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa00b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Step 1: Load and organize the data by decade\n",
    "def load_data(file_path):\n",
    "    data_by_decade = defaultdict(list)\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            time_period = record['time_period']  # Assuming there's a 'time_period' field\n",
    "            text = record['text']  # Assuming there's a 'text' field containing the text data\n",
    "            data_by_decade[time_period].append(text)\n",
    "    return data_by_decade\n",
    "\n",
    "# Step 2: Analyze lexical diversity and word frequency for each decade\n",
    "def analyze_language(data_by_decade):\n",
    "    for decade, texts in data_by_decade.items():\n",
    "        all_words = [word for text in texts for word in word_tokenize(text.lower())]\n",
    "        vocab = set(all_words)\n",
    "        lexical_diversity = len(vocab) / len(all_words)\n",
    "        freq_dist = FreqDist(all_words)\n",
    "\n",
    "        print(f\"Decade: {decade}\")\n",
    "        print(f\"Lexical Diversity: {lexical_diversity:.4f}\")\n",
    "        print(f\"Most Common Words: {freq_dist.most_common(10)}\\n\")\n",
    "\n",
    "# Assuming you have a JSON Lines file 'data.jsonl' with text data and a 'time_period' field\n",
    "file_path = 'data.jsonl'\n",
    "data_by_decade = load_data(file_path)\n",
    "analyze_language(data_by_decade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da65637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textstat.textstat import textstatistics\n",
    "\n",
    "# Load and organize the data by decade\n",
    "def load_data(file_path):\n",
    "    data_by_decade = defaultdict(list)\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            time_period = record['time_period']  # Assuming there's a 'time_period' field\n",
    "            text = record['text']  # Assuming there's a 'text' field containing the text data\n",
    "            data_by_decade[time_period].append(text)\n",
    "    return data_by_decade\n",
    "\n",
    "# Calculate average sentence length in words\n",
    "def average_sentence_length(texts):\n",
    "    sentences = [sentence for text in texts for sentence in sent_tokenize(text)]\n",
    "    words = [word for text in texts for word in word_tokenize(text)]\n",
    "    return len(words) / len(sentences)\n",
    "\n",
    "# N-gram frequency analysis\n",
    "def n_gram_analysis(texts, n=2):\n",
    "    n_grams = nltk.ngrams(' '.join(texts).split(), n)\n",
    "    freq_dist = FreqDist(n_grams)\n",
    "    return freq_dist.most_common(10)\n",
    "\n",
    "# Sentiment analysis\n",
    "def sentiment_analysis(texts):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = [sia.polarity_scores(text) for text in texts]\n",
    "    average_sentiment = defaultdict(float)\n",
    "    for score in sentiment_scores:\n",
    "        for key in score:\n",
    "            average_sentiment[key] += score[key] / len(texts)\n",
    "    return average_sentiment\n",
    "\n",
    "# Readability analysis (example: Flesch reading ease)\n",
    "def readability_analysis(texts):\n",
    "    text = ' '.join(texts)\n",
    "    return textstatistics().flesch_reading_ease(text)\n",
    "\n",
    "# Analyze language for each decade\n",
    "def analyze_language(data_by_decade):\n",
    "    for decade, texts in data_by_decade.items():\n",
    "        print(f\"Decade: {decade}\")\n",
    "        print(f\"Lexical Diversity: {len(set(word_tokenize(' '.join(texts)))) / len(word_tokenize(' '.join(texts))):.4f}\")\n",
    "        print(f\"Average Sentence Length: {average_sentence_length(texts):.2f} words\")\n",
    "        print(f\"Top Bigrams: {n_gram_analysis(texts)}\")\n",
    "        print(f\"Sentiment Scores: {sentiment_analysis(texts)}\")\n",
    "        print(f\"Flesch Reading Ease: {readability_analysis(texts):.2f}\\n\")\n",
    "\n",
    "# Example usage\n",
    "file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed807b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c42a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "class HistoricalLLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HistoricalLLM, self).__init__()\n",
    "        # Initialize with a pre-trained model or your own configuration\n",
    "        self.language_model = BertModel(BertConfig())\n",
    "        # Adapters could be added here if needed\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        return self.language_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "    def fine_tune(self, training_data_loader, learning_rate=1e-5):\n",
    "        self.train()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in training_data_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                outputs = self(input_ids, attention_mask=attention_mask)\n",
    "                loss = compute_loss(outputs, batch)  # Define compute_loss based on your task\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "class TimeCapsuleAdapter:\n",
    "    # This is the adapter we discussed earlier\n",
    "    pass\n",
    "\n",
    "# Example usage\n",
    "llm = HistoricalLLM()\n",
    "# Here you would attach an adapter, fine-tune the model, etc.\n",
    "\n",
    "# Fine-tuning the model (assuming you have a DataLoader for your historical data)\n",
    "# llm.fine_tune(training_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "class TimeCapsuleAdapter:\n",
    "    def __init__(self, model_name='gpt2', time_capsule_data=None):\n",
    "        self.model = GPT2Model.from_pretrained(model_name)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.time_capsule_data = time_capsule_data or {}\n",
    "\n",
    "    def add_memory(self, period, memory_text):\n",
    "        if period in self.time_capsule_data:\n",
    "            self.time_capsule_data[period].append(memory_text)\n",
    "        else:\n",
    "            self.time_capsule_data[period] = [memory_text]\n",
    "\n",
    "    def generate_from_period(self, period, prompt=\"\", max_length=50):\n",
    "        if period not in self.time_capsule_data:\n",
    "            return \"No memories available for this period.\"\n",
    "\n",
    "        historical_context = ' '.join(self.time_capsule_data[period])\n",
    "        full_prompt = f\"{historical_context} {prompt}\"\n",
    "        input_ids = self.tokenizer.encode(full_prompt, return_tensors='pt')\n",
    "\n",
    "        # Generating text from the model\n",
    "        output_sequences = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length + len(input_ids[0]),\n",
    "            temperature=0.9\n",
    "        )\n",
    "\n",
    "        generated_sequence = self.tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "        return generated_sequence[len(full_prompt):]  # Return only the generated part\n",
    "\n",
    "# Usage example\n",
    "time_capsule = TimeCapsuleAdapter()\n",
    "time_capsule.add_memory('1990s', 'The rise of the internet. The emergence of mobile phones.')\n",
    "generated_text = time_capsule.generate_from_period('1990s', prompt=\"In the late 90s,\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicalAdapter:\n",
    "    def __init__(self, model, period):\n",
    "        self.model = model  # The period-specific trained model\n",
    "        self.period = period  # The historical period this adapter handles\n",
    "\n",
    "    def process(self, text):\n",
    "        # Process the text using the model and return the result\n",
    "        return self.model.generate(text)\n",
    "\n",
    "class Router:\n",
    "    def __init__(self, adapters):\n",
    "        self.adapters = adapters  # A list of PeriodicalAdapter instances\n",
    "\n",
    "    def route(self, text):\n",
    "        period = self.analyze_period(text)  # Determine the period from the text\n",
    "        for adapter in self.adapters:\n",
    "            if adapter.period == period:\n",
    "                return adapter.process(text)\n",
    "        return \"Period not covered\"\n",
    "\n",
    "    def analyze_period(self, text):\n",
    "        # Analyze the text to determine the relevant time period\n",
    "        # This function needs to be implemented based on specific criteria\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518fe5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_period(text):\n",
    "    period_keywords = {\n",
    "        '1800s': ['Industrial Revolution', 'Victorian Era'],\n",
    "        '1900s': ['World War I', 'World War II', 'Cold War'],\n",
    "        '2000s': ['Internet', 'smartphone', 'social media']\n",
    "    }\n",
    "\n",
    "    for period, keywords in period_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in text.lower():\n",
    "                return period\n",
    "\n",
    "    return \"Unknown period\"  # Default if no period-specific keywords are found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b46b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_period(text, models):\n",
    "    perplexities = {period: calculate_perplexity(model, text) for period, model in models.items()}\n",
    "    # Find the period with the lowest perplexity\n",
    "    best_period = min(perplexities, key=perplexities.get)\n",
    "    return best_period\n",
    "\n",
    "# Example usage\n",
    "models = {\n",
    "    '1800s': model_1800s,\n",
    "    '1900s': model_1900s,\n",
    "    '2000s': model_2000s\n",
    "}\n",
    "\n",
    "text = \"The rise of the internet has transformed society.\"\n",
    "period = determine_period(text, models)\n",
    "print(f\"The text likely belongs to the {period} period.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4709020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8169ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef2474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c05801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509d712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21812c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8b7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887d9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75ae356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopy\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Assuming you have a dataset where entities and their years are already extracted\n",
    "# place_mentions_per_year = defaultdict(list)  # {year: [(place_name, entity)]}\n",
    "\n",
    "# # Geolocator setup\n",
    "# geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# # Example dataset iteration\n",
    "# for document in tqdm(dataset['train'], total=len(dataset['train'])):\n",
    "#     metadata = ast.literal_eval(document['metadata'])\n",
    "#     date = metadata.get('date')\n",
    "    \n",
    "#     if not date:\n",
    "#         continue  # Skip documents without a date\n",
    "\n",
    "#     year = int(date[:4])\n",
    "#     decade = year - (year % 10)\n",
    "    \n",
    "#     sentences = document['sentences']\n",
    "#     for tokens, coarse_lit, coarse_meto, fine_lit, fine_meto, fine_comp, ne_nested in zip(\n",
    "#         sentences['tokens'], sentences['NE-COARSE-LIT'], sentences['NE-COARSE-METO'],\n",
    "#         sentences['NE-FINE-LIT'], sentences['NE-FINE-METO'], sentences['NE-FINE-COMP'], sentences['NE-NESTED']\n",
    "#     ):\n",
    "#         for tags in [coarse_lit, coarse_meto, fine_lit, fine_meto, fine_comp, ne_nested]:\n",
    "#             entities = get_entities(tokens, tags)\n",
    "#             print(entities)\n",
    "#             for entity in entities:\n",
    "#                 if entity['entity'] == 'loc':  # Assuming 'type' field indicating the entity type\n",
    "#                     location = geolocator.geocode(entity['word'], exactly_one=True)\n",
    "#                     if location:\n",
    "#                         lat, lon = location.latitude, location.longitude\n",
    "#                         place_mentions_per_year[year].append((entity['word'], (lat, lon)))\n",
    "\n",
    "# # Now place_mentions_per_year contains place names and their coordinates mentioned per year\n",
    "\n",
    "# # Example: print places and their coordinates mentioned in 2020\n",
    "# for place, coords in place_mentions_per_year[2020]:\n",
    "#     print(f\"{place} at coordinates {coords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd9720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f881f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b33821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cbd36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780f3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
